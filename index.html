<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Real-time Face Recognition</title>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/face-api.js/0.22.2/face-api.min.js"></script>
  <style>
    * { margin:0; padding:0; box-sizing:border-box; }
    body {
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      background: linear-gradient(135deg,#667eea 0%,#764ba2 100%);
      min-height:100vh; display:flex; flex-direction:column; align-items:center;
      padding:20px; color:#fff;
    }
    h1 { margin:20px 0; font-size:2.2em; text-shadow:2px 2px 4px rgba(0,0,0,.3); }
    .container {
      background: rgba(255,255,255,0.08); backdrop-filter: blur(8px);
      border-radius:16px; padding:22px; box-shadow:0 8px 32px rgba(0,0,0,0.25);
      max-width:960px; width:100%;
    }
    .status { background: rgba(255,255,255,0.09); padding:12px; border-radius:10px; margin-bottom:14px; text-align:center; font-size:1em; }
    .status.loading { background: rgba(255,193,7,0.25); }
    .status.ready { background: rgba(76,175,80,0.25); }
    .status.error { background: rgba(244,67,54,0.25); }
    .camera-select { background: rgba(255,255,255,0.06); padding:16px; border-radius:10px; margin-bottom:14px; }
    .camera-select label { display:block; margin-bottom:8px; font-weight:700; }
    .camera-select select { width:100%; padding:10px; border-radius:8px; border:none; background:#fff; color:#222; font-size:1em; cursor:pointer; }
    .controls { display:flex; gap:12px; justify-content:center; margin-top:10px; flex-wrap:wrap; }
    button {
      background: rgba(255,255,255,0.18); border:2px solid rgba(255,255,255,0.35);
      color:#fff; padding:10px 20px; border-radius:20px; cursor:pointer; font-weight:700;
      transition: all .22s; text-transform:uppercase;
    }
    button:hover { transform:translateY(-3px); background: rgba(255,255,255,0.32); }
    button:disabled { opacity:.45; cursor:not-allowed; transform:none; }
    .video-container { position:relative; display:inline-block; margin:18px auto; text-align:center; }
    video { border-radius:12px; max-width:100%; display:block; box-shadow:0 6px 26px rgba(0,0,0,.35); }
    canvas { position:absolute; top:0; left:0; border-radius:12px; pointer-events:none; }
    .recognition-result {
      background: rgba(76,175,80,0.35); padding:12px; border-radius:10px; margin-top:14px; text-align:center; font-weight:700;
      min-height:48px; display:flex; align-items:center; justify-content:center;
    }
    .persons-loaded { background: rgba(255,255,255,0.06); padding:12px; border-radius:10px; margin-top:12px; font-size:.98em; }
    .persons-loaded h3 { margin-bottom:8px; font-size:1.05em; }
    .person-tag { display:inline-block; background: rgba(255,255,255,0.14); padding:6px 12px; border-radius:14px; margin:6px; font-size:.92em; color:#fff; }
    .small { font-size:.9em; opacity:.9; }
    .config-section { background: rgba(255,255,255,0.06); padding:16px; border-radius:10px; margin-bottom:14px; }
    .config-section h3 { margin-bottom:10px; font-size:1.1em; }
    .config-section textarea {
      width:100%; min-height:80px; padding:10px; border-radius:8px; border:none;
      background:rgba(255,255,255,0.9); color:#222; font-family:monospace; font-size:0.9em;
      resize:vertical;
    }
    .config-section .help {
      margin-top:8px; font-size:0.85em; opacity:0.85; line-height:1.4;
    }
  </style>
</head>
<body>
  <h1>üé≠ Real-time Face Recognition</h1>

  <div class="container">
    <div id="status" class="status loading">Loading models...</div>

    <div class="config-section">
      <h3>üìã Person Names Configuration</h3>
      <textarea id="personsConfig" placeholder='["John", "Sarah", "Mike"]'>["person1", "person2", "person3"]</textarea>
      <div class="help">
        Enter person folder names as a JSON array. Example: ["Alice", "Bob", "Charlie"]<br>
        These should match your folder names in the /database/ directory.
      </div>
    </div>

    <div class="camera-select">
      <label for="cameraSelect">üì∑ Select Camera:</label>
      <select id="cameraSelect" disabled>
        <option value="">Loading cameras...</option>
      </select>
    </div>

    <div class="controls">
      <button id="loadDataBtn">Load Database</button>
      <button id="startBtn" disabled>Start Camera</button>
      <button id="stopBtn" disabled>Stop Camera</button>
    </div>

    <div class="video-container" style="margin-top:16px;">
      <video id="video" autoplay muted playsinline></video>
      <canvas id="canvas"></canvas>
    </div>

    <div id="result" class="recognition-result">Waiting to start...</div>

    <div id="personsLoaded" class="persons-loaded" style="display:none;">
      <h3>üë• Loaded Persons:</h3>
      <div id="personsList"></div>
    </div>
  </div>

  <script>
    // Core state
    let labeledDescriptors = [];
    let faceMatcher = null;
    let video = null, canvas = null, ctx = null;
    let isVideoRunning = false;
    let currentStream = null;
    let detectionRaf = null;
    let lastDetectionTime = 0;
    const DETECTION_THROTTLE_MS = 100;

    // Wait for face-api to load
    function waitForFaceApi() {
      return new Promise((resolve) => {
        if (typeof faceapi !== 'undefined') {
          resolve();
        } else {
          const checkInterval = setInterval(() => {
            if (typeof faceapi !== 'undefined') {
              clearInterval(checkInterval);
              resolve();
            }
          }, 100);
        }
      });
    }

    // On load
    window.addEventListener('load', async () => {
      video = document.getElementById('video');
      canvas = document.getElementById('canvas');
      ctx = canvas.getContext('2d');

      // Wait for face-api library to load
      await waitForFaceApi();

      // Wire up buttons
      document.getElementById('loadDataBtn').addEventListener('click', loadTrainingData);
      document.getElementById('startBtn').addEventListener('click', startVideo);
      document.getElementById('stopBtn').addEventListener('click', stopVideo);

      await loadModels();
      await warmupCameraPermission();
      await loadCameras();
    });

    // Load face-api models
    async function loadModels() {
      const status = document.getElementById('status');
      try {
        status.textContent = 'Loading face detection models...';
        // Use the official GitHub hosted models
        const MODEL_URL = 'https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights';
        
        await faceapi.nets.ssdMobilenetv1.loadFromUri(MODEL_URL);
        await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
        await faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL);
        
        status.textContent = '‚úÖ Models loaded! Configure person names and click "Load Database"';
        status.className = 'status ready';
      } catch (e) {
        status.textContent = '‚ùå Error loading models: ' + (e.message || e);
        status.className = 'status error';
        console.error(e);
      }
    }

    // Warmup permission to reveal camera labels
    async function warmupCameraPermission() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
        stream.getTracks().forEach(t => t.stop());
      } catch (e) {
        console.warn('camera warmup failed:', e);
      }
    }

    // Populate camera select
    async function loadCameras() {
      try {
        const devices = await navigator.mediaDevices.enumerateDevices();
        const videoDevices = devices.filter(d => d.kind === 'videoinput');

        const cameraSelect = document.getElementById('cameraSelect');
        cameraSelect.innerHTML = '';

        if (videoDevices.length === 0) {
          cameraSelect.innerHTML = '<option value="">No cameras found</option>';
          cameraSelect.disabled = true;
          return;
        }

        videoDevices.forEach((device, idx) => {
          const opt = document.createElement('option');
          opt.value = device.deviceId;
          opt.textContent = device.label || `Camera ${idx+1}`;
          cameraSelect.appendChild(opt);
        });

        cameraSelect.disabled = false;
        cameraSelect.addEventListener('change', () => {
          if (isVideoRunning) {
            stopVideo();
            setTimeout(() => startVideo(), 250);
          }
        });
      } catch (e) {
        console.error('Error enumerating devices:', e);
        document.getElementById('cameraSelect').innerHTML = '<option value="">Error loading cameras</option>';
      }
    }

    // Load training images from configured persons
    async function loadTrainingData() {
      const status = document.getElementById('status');
      const loadBtn = document.getElementById('loadDataBtn');
      
      try {
        // Parse person names from config
        const configText = document.getElementById('personsConfig').value.trim();
        let persons;
        
        try {
          persons = JSON.parse(configText);
          if (!Array.isArray(persons)) {
            throw new Error('Configuration must be a JSON array');
          }
        } catch (e) {
          status.textContent = '‚ùå Invalid JSON format in person names configuration';
          status.className = 'status error';
          return;
        }

        if (persons.length === 0) {
          status.textContent = '‚ö†Ô∏è No person names configured';
          status.className = 'status error';
          return;
        }

        loadBtn.disabled = true;
        loadBtn.textContent = 'Loading...';
        status.textContent = `Loading images for ${persons.length} persons...`;
        status.className = 'status loading';
        labeledDescriptors = [];

        for (const person of persons) {
          const descriptors = [];
          const extensions = ['jpg','jpeg','png'];
          
          // Try up to 20 images per folder
          for (let i=1; i<=20; i++) {
            let got = false;
            for (const ext of extensions) {
              const imageUrl = `database/${person}/image${i}.${ext}`;
              try {
                const img = await faceapi.fetchImage(imageUrl);
                const detection = await faceapi.detectSingleFace(img).withFaceLandmarks().withFaceDescriptor();
                if (detection && detection.descriptor) {
                  descriptors.push(detection.descriptor);
                  got = true;
                  console.log(`Loaded ${person}/image${i}.${ext}`);
                  break;
                }
              } catch (e) {
                // Image may not exist; try next extension
              }
            }
            // Stop if no image found for this i (and i>1)
            if (!got && i>1) break;
          }
          
          if (descriptors.length > 0) {
            labeledDescriptors.push(new faceapi.LabeledFaceDescriptors(person, descriptors));
          }
        }

        if (labeledDescriptors.length === 0) {
          status.textContent = '‚ö†Ô∏è No valid training images found. Check folder structure.';
          status.className = 'status error';
          document.getElementById('startBtn').disabled = true;
        } else {
          // Create faceMatcher once
          faceMatcher = new faceapi.FaceMatcher(labeledDescriptors, 0.6);
          displayLoadedPersons();

          status.textContent = `‚úÖ Loaded ${labeledDescriptors.length} persons. Select camera and start!`;
          status.className = 'status ready';
          document.getElementById('startBtn').disabled = false;
        }
      } catch (e) {
        console.error('Error loading training data:', e);
        status.textContent = '‚ùå Error loading training data: ' + (e.message || e);
        status.className = 'status error';
      } finally {
        loadBtn.disabled = false;
        loadBtn.textContent = 'Load Database';
      }
    }

    function displayLoadedPersons() {
      const personsLoadedDiv = document.getElementById('personsLoaded');
      const personsList = document.getElementById('personsList');
      personsList.innerHTML = '';
      labeledDescriptors.forEach(d => {
        const tag = document.createElement('span');
        tag.className = 'person-tag';
        tag.textContent = `${d.label} (${d.descriptors.length} images)`;
        personsList.appendChild(tag);
      });
      personsLoadedDiv.style.display = 'block';
    }

    // Start camera and detection
    async function startVideo() {
      try {
        if (currentStream) {
          currentStream.getTracks().forEach(t => t.stop());
        }

        const cameraSelect = document.getElementById('cameraSelect');
        const selected = cameraSelect.value;
        const constraints = {
          video: {
            deviceId: selected ? { exact: selected } : undefined,
            width: { ideal: 640 },
            height: { ideal: 480 },
            facingMode: 'user'
          }
        };

        const stream = await navigator.mediaDevices.getUserMedia(constraints);
        currentStream = stream;
        video.srcObject = stream;
        isVideoRunning = true;

        await new Promise(resolve => {
          video.onloadedmetadata = () => {
            canvas.width = video.videoWidth || 640;
            canvas.height = video.videoHeight || 480;
            resolve();
          };
        });

        document.getElementById('startBtn').disabled = true;
        document.getElementById('stopBtn').disabled = false;
        document.getElementById('result').textContent = 'Camera started. Looking for faces...';

        if (!detectionRaf) detectionLoop();
      } catch (e) {
        alert('Error accessing camera: ' + (e.message || e));
        console.error(e);
      }
    }

    function stopVideo() {
      if (currentStream) {
        currentStream.getTracks().forEach(t => t.stop());
        currentStream = null;
      }
      if (detectionRaf) {
        cancelAnimationFrame(detectionRaf);
        detectionRaf = null;
      }
      isVideoRunning = false;
      ctx.clearRect(0,0,canvas.width,canvas.height);
      document.getElementById('startBtn').disabled = false;
      document.getElementById('stopBtn').disabled = true;
      document.getElementById('result').textContent = 'Camera stopped.';
    }

    // Main loop using requestAnimationFrame and throttling
    async function detectionLoop() {
      detectionRaf = requestAnimationFrame(detectionLoop);
      if (!isVideoRunning || !faceMatcher) return;

      const now = performance.now();
      if (now - lastDetectionTime < DETECTION_THROTTLE_MS) return;
      lastDetectionTime = now;

      try {
        const detections = await faceapi.detectAllFaces(video).withFaceLandmarks().withFaceDescriptors();
        const displaySize = { width: video.videoWidth, height: video.videoHeight };
        const resized = faceapi.resizeResults(detections, displaySize);

        ctx.clearRect(0,0,canvas.width,canvas.height);

        if (resized.length > 0) {
          const results = resized.map(d => faceMatcher.findBestMatch(d.descriptor));
          resized.forEach((detection, i) => {
            const box = detection.detection.box;
            const match = results[i];
            // Draw box
            ctx.lineWidth = 3;
            ctx.strokeStyle = '#00ff00';
            ctx.strokeRect(box.x, box.y, box.width, box.height);
            // Label background
            const text = match.toString();
            const th = 22;
            ctx.fillStyle = 'rgba(0,255,0,0.85)';
            ctx.fillRect(box.x, Math.max(0, box.y - th), box.width, th);
            // Label text
            ctx.fillStyle = '#000';
            ctx.font = '18px Arial';
            ctx.fillText(text, box.x + 6, Math.max(14, box.y - 6));
          });

          const recognizedNames = results
            .filter(r => r.label !== 'unknown')
            .map(r => r.label)
            .filter((v,i,a)=>a.indexOf(v)===i)
            .join(', ');

          if (recognizedNames) {
            document.getElementById('result').textContent = `‚úÖ Recognized: ${recognizedNames}`;
          } else {
            document.getElementById('result').textContent = '‚ùì Unknown person detected';
          }
        } else {
          document.getElementById('result').textContent = 'üîç No faces detected';
        }
      } catch (e) {
        console.error('Detection error:', e);
      }
    }

    // Stop detection when tab hidden to save CPU
    document.addEventListener('visibilitychange', () => {
      if (document.hidden) {
        if (detectionRaf) cancelAnimationFrame(detectionRaf);
        detectionRaf = null;
      } else {
        if (isVideoRunning && !detectionRaf) detectionLoop();
      }
    });

    // Resize canvas if window resized
    window.addEventListener('resize', () => {
      if (video && video.videoWidth) {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
      }
    });
  </script>
</body>
</html>
